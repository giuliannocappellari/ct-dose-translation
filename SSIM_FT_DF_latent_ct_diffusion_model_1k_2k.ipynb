{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EXvuTGmeAFc",
        "outputId": "f8a25682-10c4-4f10-8030-5351d294d77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D62kvSpPsNrF",
        "outputId": "88b34f9b-8644-49af-8a31-9d972c4afd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.31.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.2.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.4.26)\n",
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.15.2)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.2.1->lpips) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lpips\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lpips-0.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia)\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kornia) (24.2)\n",
            "Requirement already satisfied: torch>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from kornia) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.1->kornia) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.1->kornia) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.1->kornia) (3.0.2)\n",
            "Downloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kornia_rs, kornia\n",
            "Successfully installed kornia-0.8.1 kornia_rs-0.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom\n",
        "!pip install einops\n",
        "!pip install diffusers\n",
        "!pip install lpips\n",
        "!pip install kornia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh_WlzqzeM55"
      },
      "outputs": [],
      "source": [
        "import os, glob, math, functools, random\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pydicom\n",
        "import importlib\n",
        "from einops import rearrange, repeat\n",
        "from torchvision import models\n",
        "from tqdm.auto import tqdm\n",
        "from diffusers import AutoencoderKL, DDPMScheduler\n",
        "import lpips\n",
        "from torch.utils.data import random_split\n",
        "import kornia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ozlu4pztXwF"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),  # ensure it's single‑channel\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5])           # mean/std for one channel\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhyQVEfapnll"
      },
      "source": [
        "# AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "724O8cfjyZ-2"
      },
      "source": [
        "# Difusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GVBjobkzHJY"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU834ZbHzNLF"
      },
      "source": [
        "### UNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHMNNtOWybwn"
      },
      "outputs": [],
      "source": [
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "class ResnetBlockTime(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, groups=32):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.GroupNorm(groups, in_ch)\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "        self.time_mlp = nn.Sequential(Swish(), nn.Linear(time_emb_dim, out_ch * 2))\n",
        "        self.norm2 = nn.GroupNorm(groups, out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        h = self.norm1(x); h = Swish()(h); h = self.conv1(h)\n",
        "        scale, shift = self.time_mlp(t_emb).chunk(2, dim=1)\n",
        "        h = h * (scale[:, :, None, None] + 1) + shift[:, :, None, None]\n",
        "        h = self.norm2(h); h = Swish()(h); h = self.conv2(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, groups=32):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.GroupNorm(groups, in_ch)\n",
        "        self.act1  = Swish()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "\n",
        "        self.norm2 = nn.GroupNorm(groups, out_ch)\n",
        "        self.act2  = Swish()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "\n",
        "        if in_ch != out_ch:\n",
        "            self.res_conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "        else:\n",
        "            self.res_conv = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(self.act1(self.norm1(x)))\n",
        "        h = self.conv2(self.act2(self.norm2(h)))\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super().__init__()\n",
        "        self.op = nn.Conv2d(ch, ch, 4, stride=2, padding=1)\n",
        "    def forward(self, x): return self.op(x)\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, ch):\n",
        "        super().__init__()\n",
        "        self.op = nn.ConvTranspose2d(ch, ch, 4, stride=2, padding=1)\n",
        "    def forward(self, x): return self.op(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int = 1,\n",
        "        hidden_dims: list[int] = [64, 128, 256],\n",
        "        latent_dim: int = 16,\n",
        "        attn_resolutions: list[int] = [16],      # apply attention when H=W equals these\n",
        "        diffusion_embed_dim: int = 512\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # input convolution\n",
        "        self.conv_in = nn.Conv2d(in_channels, hidden_dims[0], 3, padding=1)\n",
        "\n",
        "        # build down‑stack\n",
        "        self.down_blocks = nn.ModuleList()\n",
        "        ch = hidden_dims[0]\n",
        "        for h in hidden_dims:\n",
        "            block = nn.ModuleList([ ResnetBlock(ch, h) ])\n",
        "            if h in attn_resolutions:\n",
        "                block.append(AttentionBlock(h))\n",
        "            block.append(Downsample(h))\n",
        "            self.down_blocks.append(block)\n",
        "            ch = h\n",
        "\n",
        "        # final ResNet (no downsample)\n",
        "        self.mid_block = nn.ModuleList([\n",
        "            ResnetBlock(ch, ch),\n",
        "            AttentionBlock(ch),\n",
        "            ResnetBlock(ch, ch),\n",
        "        ])\n",
        "\n",
        "        # produce μ & log var: double‑z\n",
        "        self.conv_mu_logvar = nn.Conv2d(ch, 2*latent_dim, 3, padding=1)\n",
        "\n",
        "        # quantization bridges\n",
        "        self.quant_conv     = nn.Conv2d(latent_dim, diffusion_embed_dim, 1)\n",
        "        self.post_quant_conv= nn.Conv2d(diffusion_embed_dim, latent_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv_in(x)\n",
        "        for block in self.down_blocks:\n",
        "            for layer in block:\n",
        "                h = layer(h)\n",
        "\n",
        "        for layer in self.mid_block:\n",
        "            h = layer(h)\n",
        "\n",
        "        # double‑z\n",
        "        stats = self.conv_mu_logvar(h)\n",
        "        mu, logvar = torch.chunk(stats, 2, dim=1)\n",
        "\n",
        "        # quant bridges (optional, e.g. for your diffusion embedding)\n",
        "        quant  = self.quant_conv(mu)           # maps μ→embed_dim\n",
        "        post_q = self.post_quant_conv(quant)   # back to latent_dim\n",
        "\n",
        "        return mu, logvar, post_q\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        out_channels: int = 1,\n",
        "        hidden_dims: list[int] = [256, 128, 64],\n",
        "        latent_dim: int = 16,\n",
        "        attn_resolutions: list[int] = [16], **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # initial expand\n",
        "        self.initial = nn.Conv2d(latent_dim, hidden_dims[0], 3, padding=1)\n",
        "\n",
        "        # build up‑stack\n",
        "        self.up_blocks = nn.ModuleList()\n",
        "        ch = hidden_dims[0]\n",
        "        for h in hidden_dims[1:]:\n",
        "            block = nn.ModuleList([ ResnetBlock(ch, h) ])\n",
        "            if h in attn_resolutions:\n",
        "                block.append(AttentionBlock(h))\n",
        "            block.append(Upsample(h))\n",
        "            self.up_blocks.append(block)\n",
        "            ch = h\n",
        "\n",
        "        # final conv to image\n",
        "        self.conv_out = nn.Sequential(\n",
        "            ResnetBlock(ch, ch),\n",
        "            nn.GroupNorm(32, ch),\n",
        "            Swish(),\n",
        "            Upsample(ch),\n",
        "            nn.Conv2d(ch, out_channels, 3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.initial(z)\n",
        "        for block in self.up_blocks:\n",
        "            for layer in block:\n",
        "                h = layer(h)\n",
        "        return self.conv_out(h)\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, ch, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = ch // num_heads\n",
        "        assert head_dim * num_heads == ch, \"ch must be divisible by num_heads\"\n",
        "\n",
        "        self.to_q = nn.Conv2d(ch, ch, 1)\n",
        "        self.to_k = nn.Conv2d(ch, ch, 1)\n",
        "        self.to_v = nn.Conv2d(ch, ch, 1)\n",
        "        self.proj = nn.Conv2d(ch, ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        N = H * W\n",
        "        h = self.num_heads\n",
        "        d = C // h\n",
        "\n",
        "        # project\n",
        "        q = self.to_q(x).view(B, h, d, N)\n",
        "        k = self.to_k(x).view(B, h, d, N)\n",
        "        v = self.to_v(x).view(B, h, d, N)\n",
        "\n",
        "        # scaled dot-product: (B, h, N, N)\n",
        "        attn = torch.einsum('b h d n, b h d m -> b h n m', q, k)\n",
        "        attn = attn * (d ** -0.5)\n",
        "        attn = torch.softmax(attn, dim=-1)\n",
        "\n",
        "        # attend to v → (B, h, d, N)\n",
        "        out = torch.einsum('b h n m, b h d m -> b h d n', attn, v)\n",
        "        out = out.contiguous().view(B, C, H, W)\n",
        "\n",
        "        return self.proj(out)\n",
        "\n",
        "class CrossAttentionBlock(nn.Module):\n",
        "    def __init__(self, ch, cond_ch, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.norm      = nn.GroupNorm(32, ch)\n",
        "        self.num_heads = num_heads\n",
        "        head_dim       = ch // num_heads\n",
        "        assert head_dim * num_heads == ch, \"ch must divide evenly\"\n",
        "        self.to_q = nn.Conv2d(ch, ch, 1)\n",
        "        self.to_k = nn.Conv2d(cond_ch, ch, 1)\n",
        "        self.to_v = nn.Conv2d(cond_ch, ch, 1)\n",
        "        self.proj = nn.Conv2d(ch, ch, 1)\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        B, C, H, W = x.shape\n",
        "        h = self.num_heads; d = C // h\n",
        "        x_norm = self.norm(x)\n",
        "        # match spatial size\n",
        "        if cond.shape[-2:] != (H, W):\n",
        "            cond = F.interpolate(cond, size=(H, W), mode='bilinear', align_corners=False)\n",
        "\n",
        "        q = self.to_q(x_norm).view(B, h, d, H*W).transpose(-1,-2)  # [B,h,N,d]\n",
        "        k = self.to_k(cond)   .view(B, h, d, H*W).transpose(-1,-2)\n",
        "        v = self.to_v(cond)   .view(B, h, d, H*W).transpose(-1,-2)\n",
        "\n",
        "        attn = (q @ k.transpose(-1,-2)) * (d**-0.5)\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        out  = (attn @ v).transpose(-1,-2).contiguous().view(B, C, H, W)\n",
        "        return x + self.proj(out)\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "    def forward(self, t):\n",
        "        half = self.dim // 2\n",
        "        freq = torch.exp(\n",
        "            torch.arange(half, device=t.device) * -(math.log(10000) / (half - 1))\n",
        "        )\n",
        "        args = t[:, None] * freq[None]\n",
        "        return torch.cat([args.sin(), args.cos()], dim=-1)\n",
        "\n",
        "class ResnetBlockTime(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, groups=32):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.GroupNorm(groups, in_ch)\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "        self.time_mlp = nn.Sequential(Swish(), nn.Linear(time_emb_dim, out_ch * 2))\n",
        "        self.norm2 = nn.GroupNorm(groups, out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        h = self.norm1(x); h = Swish()(h); h = self.conv1(h)\n",
        "        scale, shift = self.time_mlp(t_emb).chunk(2, dim=1)\n",
        "        h = h * (scale[:, :, None, None] + 1) + shift[:, :, None, None]\n",
        "        h = self.norm2(h); h = Swish()(h); h = self.conv2(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "\n",
        "class LatentDiffusionUNetConditional(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_ch: int = 16,\n",
        "        cond_ch: int = 16,\n",
        "        base_ch: int = 128,\n",
        "        ch_mults: tuple[int,...] = (1,2,4,8),\n",
        "        time_dim: int = 512,\n",
        "        attn_res: tuple[int,...] = (8,16)\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cond_ch = cond_ch\n",
        "        # time embedding\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPosEmb(time_dim),\n",
        "            nn.Linear(time_dim, time_dim*4), Swish(),\n",
        "            nn.Linear(time_dim*4, time_dim)\n",
        "        )\n",
        "        # initial conv: noisy + cond\n",
        "        self.init_conv = nn.Conv2d(in_ch+cond_ch, base_ch, 3, padding=1)\n",
        "        # channel sizes\n",
        "        chs = [base_ch*m for m in ch_mults]\n",
        "\n",
        "        # Down path\n",
        "        self.downs = nn.ModuleList()\n",
        "        prev_ch   = base_ch\n",
        "        for i, out_ch in enumerate(chs):\n",
        "            layers = []\n",
        "            layers.append(ResnetBlockTime(prev_ch, out_ch, time_dim))\n",
        "            if 2**i in attn_res: layers.append(AttentionBlock(out_ch))\n",
        "            layers.append(CrossAttentionBlock(out_ch, cond_ch))\n",
        "            if i < len(chs)-1: layers.append(Downsample(out_ch))\n",
        "            self.downs.append(nn.ModuleList(layers))\n",
        "            prev_ch = out_ch\n",
        "\n",
        "        # Middle\n",
        "        mid_ch = chs[-1]\n",
        "        self.mid = nn.ModuleList([\n",
        "            ResnetBlockTime(mid_ch, mid_ch, time_dim),\n",
        "            AttentionBlock(mid_ch),\n",
        "            CrossAttentionBlock(mid_ch, cond_ch),\n",
        "            ResnetBlockTime(mid_ch, mid_ch, time_dim),\n",
        "        ])\n",
        "\n",
        "        # Up path\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in range(len(chs)-1):\n",
        "            in_ch_up = chs[-1-i]\n",
        "            skip_ch  = chs[-2-i]\n",
        "            out_ch   = skip_ch\n",
        "            layers = nn.ModuleDict({\n",
        "                'upsample': Upsample(in_ch_up),\n",
        "                'resnet':   ResnetBlockTime(in_ch_up + skip_ch, out_ch, time_dim),\n",
        "                'cross':    CrossAttentionBlock(out_ch, cond_ch)\n",
        "            })\n",
        "            if 2**(len(chs)-2-i) in attn_res:\n",
        "                layers['attn'] = AttentionBlock(out_ch)\n",
        "            self.ups.append(layers)\n",
        "\n",
        "        # Final output\n",
        "        self.final = nn.Sequential(\n",
        "            nn.GroupNorm(32, chs[0]),\n",
        "            Swish(),\n",
        "            nn.Conv2d(chs[0], in_ch, 3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t, cond):\n",
        "        # x: noisy target latent [B,in_ch,H,W]\n",
        "        # cond: low-dose latent [B,cond_ch,H,W]\n",
        "        t_emb = self.time_mlp(t)\n",
        "        h     = self.init_conv(torch.cat([x, cond], dim=1))\n",
        "        skips = []\n",
        "\n",
        "        # Down\n",
        "        for block in self.downs:\n",
        "            for layer in block:\n",
        "                if isinstance(layer, Downsample):\n",
        "                    skips.append(h)\n",
        "                    h = layer(h)\n",
        "                elif isinstance(layer, CrossAttentionBlock):\n",
        "                    h = layer(h, cond)\n",
        "                else:\n",
        "                    h = layer(h, t_emb) if isinstance(layer, ResnetBlockTime) else layer(h)\n",
        "\n",
        "        # Middle\n",
        "        for layer in self.mid:\n",
        "            if isinstance(layer, CrossAttentionBlock):\n",
        "                h = layer(h, cond)\n",
        "            else:\n",
        "                h = layer(h, t_emb) if isinstance(layer, ResnetBlockTime) else layer(h)\n",
        "\n",
        "        # Up\n",
        "        for up in self.ups:\n",
        "            h = up['upsample'](h)             # 1) upsample\n",
        "            skip = skips.pop()\n",
        "            h = torch.cat([h, skip], dim=1)  # 2) concat\n",
        "            h = up['resnet'](h, t_emb)       # 3a) resnet\n",
        "            if 'attn' in up: h = up['attn'](h)       # 3b) optional self-attn\n",
        "            h = up['cross'](h, cond)                # 3c) cross-attn\n",
        "\n",
        "        return self.final(h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZsT8AK3OdWp"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def sample_ddim_guided(z_cond, scheduler, diffusion):\n",
        "    guidance_scale = 5.0\n",
        "    B = z_cond.size(0)\n",
        "    # start from pure noise\n",
        "    z = torch.randn_like(z_cond)\n",
        "\n",
        "    for t in scheduler.timesteps:\n",
        "        t_int   = int(t.item() if isinstance(t, torch.Tensor) else t)\n",
        "        t_batch = torch.full((B,), t_int, device=device, dtype=torch.long)\n",
        "\n",
        "        # 1) unconditional prediction (cond dropped → zeros)\n",
        "        eps_uncond = diffusion(z, t_batch, cond=torch.zeros_like(z_cond))\n",
        "        # 2) conditional prediction\n",
        "        eps_cond   = diffusion(z, t_batch, cond=z_cond)\n",
        "        # 3) blend for classifier-free guidance\n",
        "        eps = eps_uncond + guidance_scale * (eps_cond - eps_uncond)\n",
        "\n",
        "        # 4) take a DDIM step\n",
        "        out = scheduler.step(eps, t_int, z, return_dict=True)\n",
        "        z   = out.prev_sample\n",
        "\n",
        "    return z\n",
        "\n",
        "def load_and_preprocess(path):\n",
        "    ds  = pydicom.dcmread(path)\n",
        "    arr = ds.pixel_array.astype(float)\n",
        "    arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-5)\n",
        "    pil = Image.fromarray((arr * 255).astype(\"uint8\"))\n",
        "    return transform(pil).unsqueeze(0)"
      ],
      "metadata": {
        "id": "zdyYvFszeyH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_image(low_img_t, diffusion, vae, scheduler):\n",
        "\n",
        "  with torch.no_grad():\n",
        "      low_rgb = low_img_t.repeat(1,3,1,1)\n",
        "      enc     = vae.encode(low_rgb)\n",
        "      z_cond  = enc.latent_dist.sample() * vae.config.scaling_factor\n",
        "\n",
        "  with torch.no_grad():\n",
        "      low_rgb = low_img_t.repeat(1,3,1,1)\n",
        "      enc     = vae.encode(low_rgb)\n",
        "      z_pred = sample_ddim_guided(z_cond, scheduler, diffusion) * vae.config.scaling_factor\n",
        "\n",
        "  with torch.no_grad():\n",
        "      dec     = vae.decode(z_pred / vae.config.scaling_factor).sample\n",
        "      pred    = (dec / 2 + 0.5).clamp(0,1)[0,0]  # [H,W] float in [0,1]\n",
        "  return pred\n",
        "\n",
        "\n",
        "def predict(vae, diffusion, scheduler, low_path):\n",
        "\n",
        "    low_img_t  = load_and_preprocess(low_path).to(device)   # [1,1,H,W]\n",
        "    pred = pred_image(low_img_t, diffusion, vae, scheduler)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "wMsfE1yFe1od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\")\n",
        "\n",
        "old_out = vae.decoder.conv_out\n",
        "w2 = old_out.weight.data                             # [3, C, k, k]\n",
        "w2_gray = w2.mean(dim=0, keepdim=True)                # [1, C, k, k]\n",
        "\n",
        "new_out = nn.Conv2d(\n",
        "    in_channels=old_out.in_channels,\n",
        "    out_channels=1,\n",
        "    kernel_size=old_out.kernel_size,\n",
        "    stride=old_out.stride,\n",
        "    padding=old_out.padding,\n",
        "    bias=(old_out.bias is not None)\n",
        ")\n",
        "new_out.weight.data.copy_(w2_gray)\n",
        "if old_out.bias is not None:\n",
        "    new_out.bias.data.fill_(old_out.bias.data.mean())\n",
        "\n",
        "vae.decoder.conv_out = new_out\n",
        "\n",
        "# freeze everything\n",
        "for p in vae.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "vae.to(device).eval()\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/CT Models/VAE/pt_vae_2_epoch_100.pth\"\n",
        "state_dict = torch.load(ckpt_path, map_location=device)\n",
        "vae.load_state_dict(state_dict)\n",
        "vae.to(device).eval()\n",
        "\n",
        "latent_ch = vae.config.latent_channels\n",
        "diffusion_model = LatentDiffusionUNetConditional(\n",
        "    in_ch   = latent_ch,\n",
        "    cond_ch = latent_ch,\n",
        "    base_ch = 128,\n",
        "    ch_mults= (1,2,4,8),\n",
        "    time_dim= 512,\n",
        "    attn_res= (8,16)\n",
        ").to(device)\n",
        "ckpt = torch.load(\"/content/drive/MyDrive/CT Models/Diffusion/pt-diffusion_3_epoch_10.pth\", map_location=device)\n",
        "diffusion_model.load_state_dict(ckpt)\n",
        "diffusion_model.eval()\n",
        "\n",
        "scheduler = DDPMScheduler(\n",
        "        beta_start=1e-4,\n",
        "        beta_end=0.02,\n",
        "        beta_schedule=\"squaredcos_cap_v2\"\n",
        "    )\n",
        "scheduler.set_timesteps(1000, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "5d76f575444a486e8f20e8503732089d",
            "4ca9de55433245d4892ddee2f4c9aac2",
            "fc85b7a8225a4036af9aaa3086942e60",
            "8b015f0e23874c8d979adc28a624f4b3",
            "3ffb245b261b404e8c73113ddc5beaef",
            "80c2aa7a4a30458995b2334f88d40fed",
            "164b65988358449cabb8c6555a082bac",
            "d7380cfb08254bec9c0d94e37add97aa",
            "5f8aa3d749b74365b60a18f62f2757bb",
            "45e4ab8386514d0491962da3bdfdd257",
            "9b826807d0924627b771afb14fa7dbda",
            "42c93781340642c89d71e9b4479432e9",
            "ce7b5372560149e98e1e6143f5486aa7",
            "54e3389982284d98aa15fbb18a5ffd3f",
            "082b7a44c6a94815ad5064eaef77b05f",
            "441dfde64716433f849b30eb053e4d91",
            "de379107e5984361b7bd1367e6adf20e",
            "0d0d082eddfb4a969fd8499a93a69249",
            "0e016b0a54c2414a9c50b415c8508ee8",
            "c9ef17f47a324cd6b3044dd770ea887f",
            "ddf99a4b9ef5486bb92675ea05638566",
            "a916250f3eb8480781c206c5347dc40b"
          ]
        },
        "id": "mME7YqXBfIFj",
        "outputId": "b8449ad6-cf6e-44aa-8c40-c67a43afe070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d76f575444a486e8f20e8503732089d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42c93781340642c89d71e9b4479432e9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "image_paths = json.load(open(\"/content/drive/MyDrive/CT/image_paths.json\"))\n",
        "ssim_module = kornia.metrics.SSIM(\n",
        "    window_size=11,        # standard 11×11 Gaussian window\n",
        "    max_val=1.0,           # your images are in [0,1]\n",
        "    eps=1e-12,\n",
        "    padding='same'\n",
        ").to(device)\n",
        "results = []\n",
        "for low_path in image_paths[1_000:1_500]:\n",
        "    # 1) get your H×W prediction in [0,1]\n",
        "    pred = predict(vae, diffusion_model, scheduler, low_path).to(device)  # [H,W]\n",
        "\n",
        "    # 2) load & de-normalize your ground‐truth into [1,1,H,W]\n",
        "    gt_t = load_and_preprocess(low_path).to(device)                      # [1,1,H,W]\n",
        "    gt   = (gt_t * 0.5 + 0.5).clamp(0,1)                                  # [1,1,H,W]\n",
        "\n",
        "    # 3) reshape pred to [1,1,H,W]\n",
        "    pred_b = pred.unsqueeze(0).unsqueeze(0)                              # [1,1,H,W]\n",
        "\n",
        "    # 4) compute SSIM map & reduce\n",
        "    with torch.no_grad():\n",
        "        ssim_map   = ssim_module(pred_b, gt)                             # [1,1,H,W]\n",
        "        ssim_score = ssim_map.mean().item()                             # scalar\n",
        "\n",
        "    results.append({\"path\": low_path, \"ssim\": ssim_score})\n",
        "    import json\n",
        "    with open(\"/content/drive/MyDrive/CT/results_2000.json\", \"w\") as f:\n",
        "        json.dump(results, f)\n",
        "\n",
        "# now `results` is a list of {\"path\":…, \"ssim\":…} for each image"
      ],
      "metadata": {
        "id": "tq0e1Hmtg9t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6h9-JoqNsM-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d76f575444a486e8f20e8503732089d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ca9de55433245d4892ddee2f4c9aac2",
              "IPY_MODEL_fc85b7a8225a4036af9aaa3086942e60",
              "IPY_MODEL_8b015f0e23874c8d979adc28a624f4b3"
            ],
            "layout": "IPY_MODEL_3ffb245b261b404e8c73113ddc5beaef"
          }
        },
        "4ca9de55433245d4892ddee2f4c9aac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c2aa7a4a30458995b2334f88d40fed",
            "placeholder": "​",
            "style": "IPY_MODEL_164b65988358449cabb8c6555a082bac",
            "value": "config.json: 100%"
          }
        },
        "fc85b7a8225a4036af9aaa3086942e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7380cfb08254bec9c0d94e37add97aa",
            "max": 547,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f8aa3d749b74365b60a18f62f2757bb",
            "value": 547
          }
        },
        "8b015f0e23874c8d979adc28a624f4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e4ab8386514d0491962da3bdfdd257",
            "placeholder": "​",
            "style": "IPY_MODEL_9b826807d0924627b771afb14fa7dbda",
            "value": " 547/547 [00:00&lt;00:00, 67.1kB/s]"
          }
        },
        "3ffb245b261b404e8c73113ddc5beaef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c2aa7a4a30458995b2334f88d40fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "164b65988358449cabb8c6555a082bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7380cfb08254bec9c0d94e37add97aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8aa3d749b74365b60a18f62f2757bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45e4ab8386514d0491962da3bdfdd257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b826807d0924627b771afb14fa7dbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42c93781340642c89d71e9b4479432e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce7b5372560149e98e1e6143f5486aa7",
              "IPY_MODEL_54e3389982284d98aa15fbb18a5ffd3f",
              "IPY_MODEL_082b7a44c6a94815ad5064eaef77b05f"
            ],
            "layout": "IPY_MODEL_441dfde64716433f849b30eb053e4d91"
          }
        },
        "ce7b5372560149e98e1e6143f5486aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de379107e5984361b7bd1367e6adf20e",
            "placeholder": "​",
            "style": "IPY_MODEL_0d0d082eddfb4a969fd8499a93a69249",
            "value": "diffusion_pytorch_model.safetensors: 100%"
          }
        },
        "54e3389982284d98aa15fbb18a5ffd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e016b0a54c2414a9c50b415c8508ee8",
            "max": 334643276,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9ef17f47a324cd6b3044dd770ea887f",
            "value": 334643276
          }
        },
        "082b7a44c6a94815ad5064eaef77b05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf99a4b9ef5486bb92675ea05638566",
            "placeholder": "​",
            "style": "IPY_MODEL_a916250f3eb8480781c206c5347dc40b",
            "value": " 335M/335M [00:01&lt;00:00, 274MB/s]"
          }
        },
        "441dfde64716433f849b30eb053e4d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de379107e5984361b7bd1367e6adf20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0d082eddfb4a969fd8499a93a69249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e016b0a54c2414a9c50b415c8508ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ef17f47a324cd6b3044dd770ea887f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddf99a4b9ef5486bb92675ea05638566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a916250f3eb8480781c206c5347dc40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}